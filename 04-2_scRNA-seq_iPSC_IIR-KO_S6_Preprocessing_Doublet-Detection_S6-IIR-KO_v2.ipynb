{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Preprocessing - Doublet Detection - S6 WT\n",
    "\n",
    "Michael Sterr\n",
    "\n",
    "2022-09-19 16:14:02  \n",
    "\n",
    "\n",
    "# Setup\n",
    "\n",
    "Run following scripts before:\n",
    " * 03-x_scRNA-seq_iPSC_WT_S6_Preprocessing_QC-Filtering_XXX.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T09:23:27.277106Z",
     "start_time": "2019-04-15T09:23:25.653400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 11:12:23.485027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import scipy as sci\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.pyplot import rc_context\n",
    "import seaborn as sb\n",
    "\n",
    "# Analysis\n",
    "import muon as mu\n",
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "import scrublet as scr\n",
    "import doubletdetection\n",
    "import scvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "anndata     0.8.0\n",
      "scanpy      1.9.1\n",
      "-----\n",
      "PIL                                 8.4.0\n",
      "absl                                NA\n",
      "anyio                               NA\n",
      "astunparse                          1.6.3\n",
      "attr                                21.2.0\n",
      "babel                               2.9.1\n",
      "backcall                            0.2.0\n",
      "beta_ufunc                          NA\n",
      "binom_ufunc                         NA\n",
      "bottleneck                          1.3.2\n",
      "certifi                             2022.06.15\n",
      "cffi                                1.15.0\n",
      "chardet                             4.0.0\n",
      "charset_normalizer                  2.0.7\n",
      "chex                                0.1.1\n",
      "cloudpickle                         2.0.0\n",
      "colorama                            0.4.4\n",
      "cupy                                10.1.0\n",
      "cupy_backends                       NA\n",
      "cupyx                               NA\n",
      "cycler                              0.10.0\n",
      "cython_runtime                      NA\n",
      "dask                                2021.10.0\n",
      "dateutil                            2.8.2\n",
      "debugpy                             1.4.1\n",
      "decorator                           5.1.0\n",
      "defusedxml                          0.7.1\n",
      "deprecate                           0.3.1\n",
      "docrep                              0.3.2\n",
      "dot_parser                          NA\n",
      "doubletdetection                    4.2\n",
      "entrypoints                         0.3\n",
      "fastrlock                           0.8\n",
      "fe17a9cb4bdaf05853229027e5fef937    NA\n",
      "flatbuffers                         NA\n",
      "flax                                0.4.0\n",
      "fsspec                              2021.10.1\n",
      "gast                                NA\n",
      "google                              NA\n",
      "h5py                                3.6.0\n",
      "idna                                3.3\n",
      "igraph                              0.9.8\n",
      "importlib_resources                 NA\n",
      "ipykernel                           6.4.2\n",
      "ipython_genutils                    0.2.0\n",
      "ipywidgets                          7.6.5\n",
      "jax                                 0.3.4\n",
      "jaxlib                              0.3.2\n",
      "jedi                                0.18.0\n",
      "jinja2                              3.0.2\n",
      "joblib                              1.1.0\n",
      "json5                               NA\n",
      "jsonschema                          4.2.0\n",
      "jupyter_server                      1.11.2\n",
      "jupyterlab_server                   2.8.2\n",
      "keras_preprocessing                 1.1.2\n",
      "kiwisolver                          1.3.2\n",
      "leidenalg                           0.8.8\n",
      "llvmlite                            0.37.0\n",
      "louvain                             0.7.0\n",
      "markupsafe                          2.0.1\n",
      "matplotlib                          3.5.2\n",
      "mpl_toolkits                        NA\n",
      "msgpack                             1.0.3\n",
      "mudata                              0.2.0\n",
      "multipledispatch                    0.6.0\n",
      "muon                                0.1.2\n",
      "natsort                             8.0.0\n",
      "nbclassic                           NA\n",
      "nbformat                            5.1.3\n",
      "nbinom_ufunc                        NA\n",
      "numba                               0.54.1\n",
      "numexpr                             2.7.3\n",
      "numpy                               1.20.0\n",
      "numpyro                             0.9.1\n",
      "opt_einsum                          v3.3.0\n",
      "optax                               0.1.1\n",
      "packaging                           21.3\n",
      "pandas                              1.4.3\n",
      "parso                               0.8.2\n",
      "pexpect                             4.8.0\n",
      "phenograph                          1.5.7\n",
      "pickleshare                         0.7.5\n",
      "pkg_resources                       NA\n",
      "prometheus_client                   NA\n",
      "prompt_toolkit                      3.0.21\n",
      "psutil                              5.8.0\n",
      "ptyprocess                          0.7.0\n",
      "pvectorc                            NA\n",
      "pycparser                           2.20\n",
      "pydev_ipython                       NA\n",
      "pydevconsole                        NA\n",
      "pydevd                              2.4.1\n",
      "pydevd_concurrency_analyser         NA\n",
      "pydevd_file_utils                   NA\n",
      "pydevd_plugins                      NA\n",
      "pydevd_tracing                      NA\n",
      "pydot                               1.4.2\n",
      "pygments                            2.10.0\n",
      "pynndescent                         0.5.5\n",
      "pyparsing                           2.4.7\n",
      "pyro                                1.7.0\n",
      "pyrsistent                          NA\n",
      "pytorch_lightning                   1.6.5\n",
      "pytz                                2021.3\n",
      "requests                            2.26.0\n",
      "rich                                NA\n",
      "scipy                               1.7.1\n",
      "scrublet                            NA\n",
      "scvi                                0.17.1\n",
      "seaborn                             0.11.2\n",
      "send2trash                          NA\n",
      "session_info                        1.0.0\n",
      "six                                 1.16.0\n",
      "sklearn                             1.0.1\n",
      "sniffio                             1.2.0\n",
      "sparse                              0.13.0\n",
      "sphinxcontrib                       NA\n",
      "statsmodels                         0.13.2\n",
      "storemagic                          NA\n",
      "tensorboard                         2.7.0\n",
      "tensorflow                          2.4.4\n",
      "termcolor                           1.1.0\n",
      "terminado                           0.12.1\n",
      "texttable                           1.6.4\n",
      "threadpoolctl                       3.0.0\n",
      "tlz                                 0.11.1\n",
      "toolz                               0.11.1\n",
      "torch                               1.11.0+cu113\n",
      "torchmetrics                        0.6.0\n",
      "torchvision                         0.12.0+cu113\n",
      "tornado                             6.1\n",
      "tqdm                                4.62.3\n",
      "traitlets                           5.1.1\n",
      "tree                                0.1.6\n",
      "typing_extensions                   NA\n",
      "umap                                0.5.2\n",
      "urllib3                             1.26.7\n",
      "wcwidth                             0.2.5\n",
      "websocket                           1.2.1\n",
      "wrapt                               1.12.1\n",
      "yaml                                5.4.1\n",
      "zipp                                NA\n",
      "zmq                                 22.3.0\n",
      "-----\n",
      "IPython             7.29.0\n",
      "jupyter_client      7.0.6\n",
      "jupyter_core        4.9.1\n",
      "jupyterlab          3.2.4\n",
      "notebook            6.4.5\n",
      "-----\n",
      "Python 3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:57:06) [GCC 9.4.0]\n",
      "Linux-5.15.0-48-generic-x86_64-with-glibc2.10\n",
      "-----\n",
      "Session information updated at 2022-10-05 11:12\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "\n",
    "## Scanpy settings\n",
    "sc.settings.verbosity = 3\n",
    "sc.logging.print_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T09:23:29.016609Z",
     "start_time": "2019-04-15T09:23:28.667840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Color maps\n",
    "exec(open(\"/home/michi/Software/viscm/maps/michi_bk_bl_gn_yl.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T09:23:30.907616Z",
     "start_time": "2019-04-15T09:23:30.903744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "%matplotlib inline\n",
    "\n",
    "## Directory\n",
    "sc.settings.figdir='/home/michi/Projects/scRNA-seq_iPSC_IGFRL-KO_Notebooks/Figures'\n",
    "\n",
    "## Plotting parameters\n",
    "rcParams['figure.figsize']=(20,20) #rescale figures\n",
    "#sc.set_figure_params(scanpy=True, frameon=False, vector_friendly=False, color_map='tab10' ,transparent=True, dpi=150, dpi_save=300)\n",
    "sc.set_figure_params(scanpy=True, frameon=False, vector_friendly=False ,transparent=True, dpi=150, dpi_save=300)\n",
    "\n",
    "## Font\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Source Sans 3']\n",
    "\n",
    "## Grid & Ticks\n",
    "rcParams['grid.alpha'] = 0\n",
    "rcParams['xtick.bottom'] = True\n",
    "rcParams['ytick.left'] = True\n",
    "\n",
    "## Embed font\n",
    "plt.rc('pdf', fonttype=42)\n",
    "\n",
    "## Define new default settings\n",
    "plt.rcParamsDefault = plt.rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R\n",
    "import os\n",
    "os.environ['R_HOME'] = '/home/michi/Software/venvs/scAnalysis_sc1.9_ad0.8_mu0.1.2_md0.2_R4.1_FVF/lib/R' #path to your R installation\n",
    "\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import rpy2.rinterface_lib.callbacks\n",
    "from rpy2.robjects import pandas2ri\n",
    "import anndata2ri\n",
    "\n",
    "## R settings\n",
    "\n",
    "### Ignore R warning messages\n",
    "#### Note: this can be commented out to get more verbose R output\n",
    "rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "\n",
    "### Automatically convert rpy2 outputs to pandas dataframes\n",
    "pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/home/michi/Software/venvs/scAnalysis_sc1.9_ad0.8_mu0.1.2_md0.2_R4.1_FVF/lib/R/library\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    ".libPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R version 4.1.1 (2021-08-10)\n",
      "Platform: x86_64-pc-linux-gnu (64-bit)\n",
      "Running under: Ubuntu 20.04.5 LTS\n",
      "\n",
      "Matrix products: default\n",
      "BLAS/LAPACK: /home/michi/Software/venvs/scAnalysis_sc1.9_ad0.8_mu0.1.2_md0.2_R4.1_FVF/lib/libopenblasp-r0.3.18.so\n",
      "\n",
      "locale:\n",
      " [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n",
      " [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=en_US.UTF-8    \n",
      " [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=en_US.UTF-8   \n",
      " [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 \n",
      " [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n",
      "[11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       \n",
      "\n",
      "attached base packages:\n",
      "[1] tools     stats     graphics  grDevices utils     datasets  methods  \n",
      "[8] base     \n",
      "\n",
      "loaded via a namespace (and not attached):\n",
      "[1] compiler_4.1.1\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "# # Parallelization\n",
    "# library(\"BiocParallel.FutureParam\")\n",
    "# register(FutureParam())\n",
    "# plan(multicore, workers=64)\n",
    "# options(future.globals.maxSize = 128 * 1024 ^ 3) # for 50 Gb RAM\n",
    "\n",
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(\n",
    "    clf,\n",
    "    show=False,\n",
    "    save=None,\n",
    "    log10=True,\n",
    "    log_p_grid=None,\n",
    "    voter_grid=None,\n",
    "    v_step=2,\n",
    "    p_step=5,\n",
    "):\n",
    "    \"\"\"Produce a plot showing number of cells called doublet across\n",
    "       various thresholds\n",
    "    Args:\n",
    "        clf (BoostClassifier object): Fitted classifier\n",
    "        show (bool, optional): If True, runs plt.show()\n",
    "        save (str, optional): If provided, the figure is saved to this\n",
    "            filepath.\n",
    "        log10 (bool, optional): Use log 10 if true, natural log if false.\n",
    "        log_p_grid (ndarray, optional): log p-value thresholds to use.\n",
    "            Defaults to np.arange(-100, -1). log base decided by log10\n",
    "        voter_grid (ndarray, optional): Voting thresholds to use. Defaults to\n",
    "            np.arange(0.3, 1.0, 0.05).\n",
    "        p_step (int, optional): number of xlabels to skip in plot\n",
    "        v_step (int, optional): number of ylabels to skip in plot\n",
    "    Returns:\n",
    "        matplotlib figure\n",
    "    \"\"\"\n",
    "    import warnings\n",
    "    # Ignore numpy complaining about np.nan comparisons\n",
    "    with np.errstate(invalid=\"ignore\"):\n",
    "        all_log_p_values_ = np.copy(clf.all_log_p_values_)\n",
    "        if log10:\n",
    "            all_log_p_values_ /= np.log(10)\n",
    "        if log_p_grid is None:\n",
    "            log_p_grid = np.arange(-100, -1)\n",
    "        if voter_grid is None:\n",
    "            voter_grid = np.arange(0.3, 1.0, 0.05)\n",
    "        doubs_per_t = np.zeros((len(voter_grid), len(log_p_grid)))\n",
    "        for i in range(len(voter_grid)):\n",
    "            for j in range(len(log_p_grid)):\n",
    "                voting_average = np.mean(\n",
    "                    np.ma.masked_invalid(all_log_p_values_) <= log_p_grid[j], axis=0\n",
    "                )\n",
    "                labels = np.ma.filled((voting_average >= voter_grid[i]).astype(float), np.nan)\n",
    "                doubs_per_t[i, j] = np.nansum(labels)\n",
    "\n",
    "    # Ignore warning for convergence plot\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(action=\"ignore\", module=\"matplotlib\", message=\"^tight_layout\")\n",
    "\n",
    "        f, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=150)\n",
    "        cax = ax.imshow(doubs_per_t, cmap=\"turbo\", aspect=\"auto\")\n",
    "        ax.set_xticks(np.arange(len(log_p_grid))[::p_step])\n",
    "        ax.set_xticklabels(np.around(log_p_grid, 1)[::p_step], rotation=\"vertical\")\n",
    "        ax.set_yticks(np.arange(len(voter_grid))[::v_step])\n",
    "        ax.set_yticklabels(np.around(voter_grid, 2)[::v_step])\n",
    "        cbar = f.colorbar(cax)\n",
    "        cbar.set_label(\"Predicted Doublets\")\n",
    "        if log10 is True:\n",
    "            ax.set_xlabel(\"Log10 p-value\")\n",
    "        else:\n",
    "            ax.set_xlabel(\"Log p-value\")\n",
    "        ax.set_ylabel(\"Voting Threshold\")\n",
    "        ax.set_title(\"Threshold Diagnostics\")\n",
    "\n",
    "    if show is True:\n",
    "        plt.show()\n",
    "    if save:\n",
    "        f.savefig(save, format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "def run_scDblFinder(adata, force_reload=False, layer=None, n_core=64, max_memory_gb=128):\n",
    "    '''\n",
    "    adata: adata object to normalize\n",
    "    layer: layer to use for normalization. Default = None -> use .X\n",
    "    force_reload: Force transfer of count data to R\n",
    "    '''\n",
    "    \n",
    "    import rpy2\n",
    "    import rpy2.robjects as ro\n",
    "    import gc\n",
    "\n",
    "       \n",
    "    print('Finding doublets with scDblFinder:')\n",
    "    # load packages\n",
    "    ro.globalenv['n_core'] = n_core\n",
    "    ro.globalenv['max_memory'] = max_memory_gb #/n_core\n",
    "    ro.r('''\n",
    "    print(paste0(\"Cores: \", n_core))\n",
    "    print(paste0(\"Memory: \", max_memory))\n",
    "    ''')\n",
    "    ro.r('''\n",
    "\n",
    "    # Analysis\n",
    "    library(Seurat)\n",
    "    library(sctransform)\n",
    "    library(scDblFinder)\n",
    "    library(SingleCellExperiment)\n",
    "    library(scater)\n",
    "    library(pastecs)\n",
    "\n",
    "    # Parallelization\n",
    "    library(\"BiocParallel.FutureParam\")\n",
    "    register(FutureParam())\n",
    "    plan(multicore, workers=n_core)\n",
    "    options(future.globals.maxSize = max_memory * 1024^3)\n",
    "    ''')\n",
    "    # transfer data\n",
    "    print('\\tTransfer data...')\n",
    "    \n",
    "    # check if data is in R workspace\n",
    "    if ro.r('''exists('data_mat')''')[0] == 1:\n",
    "        # check if data has same shape\n",
    "        if ro.globalenv['data_mat'].shape == adata.X.T.shape:\n",
    "            load_data = False\n",
    "            print('\\t\\tFound data matrix of same shape. Skipping data transfer...')\n",
    "        else:\n",
    "            load_data = True\n",
    "    else:\n",
    "        load_data = True\n",
    "        \n",
    "    if force_reload:\n",
    "        load_data = True\n",
    "    \n",
    "    if load_data:\n",
    "        if layer is None:\n",
    "            ro.globalenv['data_mat'] = adata.X.T#.toarray()\n",
    "            ro.globalenv['obs_names'] = adata.obs_names\n",
    "            ro.globalenv['var_names'] = adata.var_names\n",
    "        else:\n",
    "            print('\\tUsing layer \\'', layer,'\\'...')\n",
    "            ro.globalenv['data_mat'] = adata.layers[layer].T#.toarray()\n",
    "            ro.globalenv['obs_names'] = adata.obs_names\n",
    "            ro.globalenv['var_names'] = adata.var_names\n",
    "        \n",
    "        ro.r('''\n",
    "        rownames(data_mat) <- var_names\n",
    "        colnames(data_mat) <- obs_names\n",
    "        ''') \n",
    "    # standart preprocessing\n",
    "    ## create Seurat object    \n",
    "    ro.r('''\n",
    "    seurat <- CreateSeuratObject(counts = data_mat, project = \"0\", min.cells = 0, min.features = 0)\n",
    "    ''')   \n",
    "    ## preprocessing\n",
    "    print('\\tDoublet Detection with standard normalization...')\n",
    "    print('\\t\\tPreprocessing...')\n",
    "    ro.r('''\n",
    "    seurat <- NormalizeData(seurat, verbose = FALSE)\n",
    "    seurat <- FindVariableFeatures(seurat, selection.method = \"vst\", nfeatures = 5000, verbose = FALSE)\n",
    "    seurat <- ScaleData(seurat, verbose = FALSE)\n",
    "    seurat <- RunPCA(seurat, npcs = 50, verbose = FALSE)\n",
    "    seurat <- RunUMAP(seurat, reduction = \"pca\", dims = 1:50)\n",
    "    seurat <- FindNeighbors(seurat, dims = 1:50, verbose = FALSE)\n",
    "    seurat <- FindClusters(seurat, verbose = FALSE, resolution = 0.5)\n",
    "    #print(DimPlot(seurat, label = TRUE))\n",
    "    \n",
    "    #Conversion to SingleCellExperiment\n",
    "    sce <- as.SingleCellExperiment(seurat)\n",
    "    ''')\n",
    "    ## run scDblFinder\n",
    "    print('\\t\\tRunning scDblFinder...')\n",
    "    ro.r('''\n",
    "    #scDblFinder\n",
    "    colData(sce)$scoresDoubletDensity <- computeDoubletDensity(sce)\n",
    "    sce <- scDblFinder(sce, clusters = FALSE) #, dbr=0.1)\n",
    "    ''')\n",
    "    \n",
    "    \n",
    "    ## get results   \n",
    "    print('\\t\\tCollect results...')\n",
    "    ro.r('''\n",
    "    results <- colData(sce)[,c(\"scDblFinder.class\", \"scDblFinder.score\")]    \n",
    "    ''')\n",
    "    \n",
    "    # sct preprocessing\n",
    "    ## create Seurat object    \n",
    "    ro.r('''\n",
    "    seurat <- CreateSeuratObject(counts = data_mat, project = \"0\", min.cells = 0, min.features = 0)\n",
    "    ''')   \n",
    "    ## preprocessing\n",
    "    print('\\tDoublet Detection with SCT normalization...')\n",
    "    print('\\t\\tPreprocessing...')\n",
    "    ro.r('''\n",
    "    seurat <- SCTransform(seurat, verbose = FALSE)\n",
    "    seurat <- RunPCA(seurat, npcs = 50, verbose = FALSE)\n",
    "    seurat <- RunUMAP(seurat, reduction = \"pca\", dims = 1:50)\n",
    "    seurat <- FindNeighbors(seurat, dims = 1:50, verbose = FALSE)\n",
    "    seurat <- FindClusters(seurat, verbose = FALSE, resolution = 0.5)\n",
    "    #print(DimPlot(seurat, label = TRUE))\n",
    "    \n",
    "    #Conversion to SingleCellExperiment\n",
    "    sce <- as.SingleCellExperiment(seurat)\n",
    "    ''')\n",
    "    ## run scDblFinder\n",
    "    print('\\t\\tRunning scDblFinder...')\n",
    "    ro.r('''\n",
    "    #scDblFinder\n",
    "    colData(sce)$scoresDoubletDensity <- computeDoubletDensity(sce)\n",
    "    sce <- scDblFinder(sce, clusters = FALSE) #, dbr=0.1)\n",
    "    ''')\n",
    "    \n",
    "    \n",
    "    ## get results   \n",
    "    print('\\t\\tCollect results...')\n",
    "    ro.r('''\n",
    "    results <- cbind(results, colData(sce)[,c(\"scDblFinder.class\", \"scDblFinder.score\")])\n",
    "    colnames(results) <- c(\"scDblFinder.class\", \"scDblFinder.score\", \"scDblFinder.class.sct\", \"scDblFinder.score.sct\")\n",
    "    ''')\n",
    "    print('\\t\\tAdd results to anndata...')\n",
    "    results = ro.globalenv['results']\n",
    "    \n",
    "    # check if results are already present in adata.obs and delete\n",
    "    if 'scDblFinder.class' in adata.obs.columns:\n",
    "        del adata.obs[[\"scDblFinder.class.sct\", \"scDblFinder.score.sct\", \"scDblFinder.class.sct\", \"scDblFinder.score.sct\"]]\n",
    "    \n",
    "    adata.obs = pd.merge(adata.obs,results, left_index=True, right_index=True) #adata.obs[[\"scDblFinder.class.sct\", \"scDblFinder.score.sct\"]] = results.copy()\n",
    "    \n",
    "    adata.obs.loc[:,'sdf_doublets'] = False\n",
    "    adata.obs.loc[adata.obs.loc[:,'scDblFinder.class']=='doublet','sdf_doublets'] = True\n",
    "    adata.obs.loc[adata.obs.loc[:,'scDblFinder.class.sct']=='doublet','sdf_doublets'] = True\n",
    "    \n",
    "    print('\\n\\n------------------------------------------------------------------------------------\\n------------------------------------------------------------------------------------' )\n",
    "    print('\\nscDblFinder doublet rate:', adata.obs['sdf_doublets'].value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',adata.obs['sdf_doublets'].value_counts()[1],' cells)' )\n",
    "    \n",
    "    #return adata\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_SCDS(adata, force_reload=False, layer=None, n_core=64, max_memory_gb=128):\n",
    "    '''\n",
    "    adata: adata object to normalize\n",
    "    layer: layer to use for normalization. Default = None -> use .X\n",
    "    force_reload: Force transfer of count data to R\n",
    "    '''\n",
    "    \n",
    "    import rpy2\n",
    "    import rpy2.robjects as ro\n",
    "    import gc\n",
    "\n",
    "       \n",
    "    print('Finding doublets with scDblFinder:')\n",
    "    # load packages\n",
    "    ro.globalenv['n_core'] = n_core\n",
    "    ro.globalenv['max_memory'] = max_memory_gb #/n_core\n",
    "    ro.r('''\n",
    "    print(paste0(\"Cores: \", n_core))\n",
    "    print(paste0(\"Memory: \", max_memory))\n",
    "    ''')\n",
    "    ro.r('''\n",
    "\n",
    "    # Analysis\n",
    "    library(Seurat)\n",
    "    library(sctransform)\n",
    "    library(scds)\n",
    "    library(SingleCellExperiment)\n",
    "    library(scater)\n",
    "    library(pastecs)\n",
    "\n",
    "    # Parallelization\n",
    "    library(\"BiocParallel.FutureParam\")\n",
    "    register(FutureParam())\n",
    "    plan(multicore, workers=n_core)\n",
    "    options(future.globals.maxSize = max_memory * 1024^3)\n",
    "    ''')\n",
    "    # transfer data\n",
    "    print('\\tTransfer data...')\n",
    "    \n",
    "    # check if data is in R workspace\n",
    "    if ro.r('''exists('data_mat')''')[0] == 1:\n",
    "        # check if data has same shape\n",
    "        if ro.globalenv['data_mat'].shape == adata.X.T.shape:\n",
    "            load_data = False\n",
    "            print('\\t\\tFound data matrix of same shape. Skipping data transfer...')\n",
    "        else:\n",
    "            load_data = True\n",
    "    else:\n",
    "        load_data = True\n",
    "        \n",
    "    if force_reload:\n",
    "        load_data = True\n",
    "    \n",
    "    if load_data:\n",
    "        if layer is None:\n",
    "            ro.globalenv['data_mat'] = adata.X.T#.toarray()\n",
    "            ro.globalenv['obs_names'] = adata.obs_names\n",
    "            ro.globalenv['var_names'] = adata.var_names\n",
    "        else:\n",
    "            print('\\tUsing layer \\'', layer,'\\'...')\n",
    "            ro.globalenv['data_mat'] = adata.layers[layer].T#.toarray()\n",
    "            ro.globalenv['obs_names'] = adata.obs_names\n",
    "            ro.globalenv['var_names'] = adata.var_names\n",
    "        \n",
    "        ro.r('''\n",
    "        rownames(data_mat) <- var_names\n",
    "        colnames(data_mat) <- obs_names\n",
    "        ''') \n",
    "    # standart preprocessing\n",
    "    ## create Seurat object    \n",
    "    ro.r('''\n",
    "    seurat <- CreateSeuratObject(counts = data_mat, project = \"0\", min.cells = 0, min.features = 0)\n",
    "    ''')   \n",
    "    ## preprocessing\n",
    "    print('\\tDoublet Detection with standard normalization...')\n",
    "    print('\\t\\tPreprocessing...')\n",
    "    ro.r('''\n",
    "    seurat <- NormalizeData(seurat, verbose = FALSE)\n",
    "    seurat <- FindVariableFeatures(seurat, selection.method = \"vst\", nfeatures = 5000, verbose = FALSE)\n",
    "    seurat <- ScaleData(seurat, verbose = FALSE)\n",
    "    seurat <- RunPCA(seurat, npcs = 50, verbose = FALSE)\n",
    "    seurat <- RunUMAP(seurat, reduction = \"pca\", dims = 1:50)\n",
    "    seurat <- FindNeighbors(seurat, dims = 1:50, verbose = FALSE)\n",
    "    seurat <- FindClusters(seurat, verbose = FALSE, resolution = 0.5)\n",
    "    #print(DimPlot(seurat, label = TRUE))\n",
    "    \n",
    "    #Conversion to SingleCellExperiment\n",
    "    sce <- as.SingleCellExperiment(seurat)\n",
    "    ''')\n",
    "    ## run SCDS\n",
    "    print('\\t\\tRunning SCDS...')\n",
    "    ro.r('''\n",
    "    # SCDS\n",
    "    sce <- cxds(sce, retRes = TRUE)\n",
    "    sce <- bcds(sce, retRes = TRUE, verb=TRUE)\n",
    "    sce <- cxds_bcds_hybrid(sce)\n",
    "    \n",
    "    dens <- density(sce$hybrid_score)\n",
    "    min_idx <- match(-1, extract(turnpoints(dens$y, calc.proba = TRUE)))\n",
    "    cut_off <- dens$x[min_idx[length(min_idx)]]\n",
    "    \n",
    "    #print(ggplot(as.data.frame(colData(sce)), aes(x=hybrid_score)) + geom_density() + geom_vline(xintercept = cut_off, linetype=2))\n",
    "    \n",
    "    sce$hybrid_class <- \"doublet\"\n",
    "    sce[,sce$hybrid_score < cut_off]$hybrid_class <- \"singlet\"\n",
    "    ''')\n",
    "    \n",
    "    \n",
    "    ## get results   \n",
    "    print('\\t\\tCollect results...')\n",
    "    ro.r('''\n",
    "    results <- colData(sce)[,c(\"hybrid_class\", \"hybrid_score\")]    \n",
    "    ''')\n",
    "    \n",
    "    # sct preprocessing\n",
    "    ## create Seurat object    \n",
    "    ro.r('''\n",
    "    seurat <- CreateSeuratObject(counts = data_mat, project = \"0\", min.cells = 0, min.features = 0)\n",
    "    ''')   \n",
    "    ## preprocessing\n",
    "    print('\\tDoublet Detection with SCT normalization...')\n",
    "    print('\\t\\tPreprocessing...')\n",
    "    ro.r('''\n",
    "    seurat <- SCTransform(seurat, verbose = FALSE)\n",
    "    seurat <- RunPCA(seurat, npcs = 50, verbose = FALSE)\n",
    "    seurat <- RunUMAP(seurat, reduction = \"pca\", dims = 1:50)\n",
    "    seurat <- FindNeighbors(seurat, dims = 1:50, verbose = FALSE)\n",
    "    seurat <- FindClusters(seurat, verbose = FALSE, resolution = 0.5)\n",
    "    #print(DimPlot(seurat, label = TRUE))\n",
    "    \n",
    "    #Conversion to SingleCellExperiment\n",
    "    sce <- as.SingleCellExperiment(seurat)\n",
    "    ''')\n",
    "    ## run SCDS\n",
    "    print('\\t\\tRunning SCDS...')\n",
    "    ro.r('''\n",
    "    # SCDS\n",
    "    sce <- cxds(sce, retRes = TRUE)\n",
    "    sce <- bcds(sce, retRes = TRUE, verb=TRUE)\n",
    "    sce <- cxds_bcds_hybrid(sce)\n",
    "    \n",
    "    dens <- density(sce$hybrid_score)\n",
    "    min_idx <- match(-1, extract(turnpoints(dens$y, calc.proba = TRUE)))\n",
    "    cut_off <- dens$x[min_idx[length(min_idx)]]\n",
    "    \n",
    "    #print(ggplot(as.data.frame(colData(sce)), aes(x=hybrid_score)) + geom_density() + geom_vline(xintercept = cut_off, linetype=2))\n",
    "    \n",
    "    sce$hybrid_class <- \"doublet\"\n",
    "    sce[,sce$hybrid_score < cut_off]$hybrid_class <- \"singlet\"\n",
    "    ''')\n",
    "    \n",
    "    \n",
    "    ## get results   \n",
    "    print('\\t\\tCollect results...')\n",
    "    ro.r('''\n",
    "    results <- cbind(results, colData(sce)[,c(\"hybrid_class\", \"hybrid_score\")])\n",
    "    colnames(results) <- c(\"hybrid_class\", \"hybrid_score\", \"hybrid_class_sct\", \"hybrid_score_sct\")\n",
    "    ''')\n",
    "    print('\\t\\tAdd results to anndata...')\n",
    "    results = ro.globalenv['results']\n",
    "    \n",
    "    # check if results are already present in adata.obs and delete\n",
    "    if 'hybrid_class' in adata.obs.columns:\n",
    "        del adata.obs[[\"hybrid_class\", \"hybrid_score\", \"hybrid_class_sct\", \"hybrid_score_sct\"]]\n",
    "    \n",
    "    adata.obs = pd.merge(adata.obs,results, left_index=True, right_index=True) \n",
    "    \n",
    "    adata.obs.loc[:,'scds_doublets'] = False\n",
    "    adata.obs.loc[adata.obs.loc[:,'hybrid_class']=='doublet','scds_doublets'] = True\n",
    "    adata.obs.loc[adata.obs.loc[:,'hybrid_class_sct']=='doublet','scds_doublets'] = True\n",
    "    \n",
    "    print('\\n\\n------------------------------------------------------------------------------------\\n------------------------------------------------------------------------------------' )\n",
    "    print('\\nScds doublet rate:', adata.obs['scds_doublets'].value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',adata.obs['scds_doublets'].value_counts()[1],' cells)' )\n",
    "    \n",
    "#     return adata\n",
    " \n",
    "\n",
    "\n",
    "##################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_DoubletFinder(adata, force_reload=False, layer=None, n_core=64, max_memory_gb=128):\n",
    "    '''\n",
    "    adata: adata object to normalize\n",
    "    layer: layer to use for normalization. Default = None -> use .X\n",
    "    force_reload: Force transfer of count data to R\n",
    "    '''\n",
    "    \n",
    "    import rpy2\n",
    "    import rpy2.robjects as ro\n",
    "    import gc\n",
    "\n",
    "       \n",
    "    print('Finding doublets with scDblFinder:')\n",
    "    # load packages\n",
    "    ro.globalenv['n_core'] = n_core\n",
    "    ro.globalenv['max_memory'] = max_memory_gb #/n_core\n",
    "    ro.r('''\n",
    "    print(paste0(\"Cores: \", n_core))\n",
    "    print(paste0(\"Memory: \", max_memory))\n",
    "    ''')\n",
    "    ro.r('''\n",
    "\n",
    "    # Analysis\n",
    "    library(Seurat)\n",
    "    library(sctransform)\n",
    "    library(DoubletFinder)\n",
    "    library(SingleCellExperiment)\n",
    "    library(scater)\n",
    "    library(pastecs)\n",
    "\n",
    "    # Parallelization\n",
    "    library(\"BiocParallel.FutureParam\")\n",
    "    register(FutureParam())\n",
    "    plan(multicore, workers=n_core)\n",
    "    options(future.globals.maxSize = max_memory * 1024^3)\n",
    "    \n",
    "    # Adaption of original funtion to omit plot (https://github.com/chris-mcginnis-ucsf/DoubletFinder/blob/5dfd96b06365d7843adf3a72ffb6a30f42c74a01/R/find.pK.R)\n",
    "    find.pK.noPlot <- function(sweep.stats) {\n",
    "\n",
    "      ## Implementation for data without ground-truth doublet classifications \n",
    "      '%ni%' <- Negate('%in%')\n",
    "      if (\"AUC\" %ni% colnames(sweep.stats) == TRUE) {\n",
    "        ## Initialize data structure for results storage\n",
    "        bc.mvn <- as.data.frame(matrix(0L, nrow=length(unique(sweep.stats$pK)), ncol=5))\n",
    "        colnames(bc.mvn) <- c(\"ParamID\",\"pK\",\"MeanBC\",\"VarBC\",\"BCmetric\")\n",
    "        bc.mvn$pK <- unique(sweep.stats$pK)\n",
    "        bc.mvn$ParamID <- 1:nrow(bc.mvn)\n",
    "\n",
    "        ## Compute bimodality coefficient mean, variance, and BCmvn across pN-pK sweep results\n",
    "        x <- 0\n",
    "        for (i in unique(bc.mvn$pK)) {\n",
    "          x <- x + 1\n",
    "          ind <- which(sweep.stats$pK == i)\n",
    "          bc.mvn$MeanBC[x] <- mean(sweep.stats[ind, \"BCreal\"])\n",
    "          bc.mvn$VarBC[x] <- sd(sweep.stats[ind, \"BCreal\"])^2\n",
    "          bc.mvn$BCmetric[x] <- mean(sweep.stats[ind, \"BCreal\"])/(sd(sweep.stats[ind, \"BCreal\"])^2)\n",
    "        }\n",
    "\n",
    "        return(bc.mvn)\n",
    "\n",
    "      }\n",
    "\n",
    "      ## Implementation for data with ground-truth doublet classifications (e.g., MULTI-seq, CellHashing, Demuxlet, etc.)\n",
    "      if (\"AUC\" %in% colnames(sweep.stats) == TRUE) {\n",
    "        ## Initialize data structure for results storage\n",
    "        bc.mvn <- as.data.frame(matrix(0L, nrow=length(unique(sweep.stats$pK)), ncol=6))\n",
    "        colnames(bc.mvn) <- c(\"ParamID\",\"pK\",\"MeanAUC\",\"MeanBC\",\"VarBC\",\"BCmetric\")\n",
    "        bc.mvn$pK <- unique(sweep.stats$pK)\n",
    "        bc.mvn$ParamID <- 1:nrow(bc.mvn)\n",
    "\n",
    "        ## Compute bimodality coefficient mean, variance, and BCmvn across pN-pK sweep results\n",
    "        x <- 0\n",
    "        for (i in unique(bc.mvn$pK)) {\n",
    "          x <- x + 1\n",
    "          ind <- which(sweep.stats$pK == i)\n",
    "          bc.mvn$MeanAUC[x] <- mean(sweep.stats[ind, \"AUC\"])\n",
    "          bc.mvn$MeanBC[x] <- mean(sweep.stats[ind, \"BCreal\"])\n",
    "          bc.mvn$VarBC[x] <- sd(sweep.stats[ind, \"BCreal\"])^2\n",
    "          bc.mvn$BCmetric[x] <- mean(sweep.stats[ind, \"BCreal\"])/(sd(sweep.stats[ind, \"BCreal\"])^2)\n",
    "        }\n",
    "\n",
    "        return(bc.mvn)\n",
    "\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    ''')\n",
    "    # transfer data\n",
    "    print('\\tTransfer data...')\n",
    "    \n",
    "    # check if data is in R workspace\n",
    "    if ro.r('''exists('data_mat')''')[0] == 1:\n",
    "        # check if data has same shape\n",
    "        if ro.globalenv['data_mat'].shape == adata.X.T.shape:\n",
    "            load_data = False\n",
    "            print('\\t\\tFound data matrix of same shape. Skipping data transfer...')\n",
    "        else:\n",
    "            load_data = True\n",
    "    else:\n",
    "        load_data = True\n",
    "        \n",
    "    if force_reload:\n",
    "        load_data = True\n",
    "    \n",
    "    if load_data:\n",
    "        if layer is None:\n",
    "            ro.globalenv['data_mat'] = adata.X.T#.toarray()\n",
    "            ro.globalenv['obs_names'] = adata.obs_names\n",
    "            ro.globalenv['var_names'] = adata.var_names\n",
    "        else:\n",
    "            print('\\tUsing layer \\'', layer,'\\'...')\n",
    "            ro.globalenv['data_mat'] = adata.layers[layer].T#.toarray()\n",
    "            ro.globalenv['obs_names'] = adata.obs_names\n",
    "            ro.globalenv['var_names'] = adata.var_names\n",
    "        \n",
    "        ro.r('''\n",
    "        rownames(data_mat) <- var_names\n",
    "        colnames(data_mat) <- obs_names\n",
    "        ''') \n",
    "    # standart preprocessing\n",
    "    ## create Seurat object    \n",
    "    ro.r('''\n",
    "    seurat <- CreateSeuratObject(counts = data_mat, project = \"0\", min.cells = 0, min.features = 0)\n",
    "    ''')   \n",
    "    ## preprocessing\n",
    "    print('\\tDoublet Detection with standard normalization...')\n",
    "    print('\\t\\tPreprocessing...')\n",
    "    ro.r('''\n",
    "    seurat <- NormalizeData(seurat, verbose = FALSE)\n",
    "    seurat <- FindVariableFeatures(seurat, selection.method = \"vst\", nfeatures = 5000, verbose = FALSE)\n",
    "    seurat <- ScaleData(seurat, verbose = FALSE)\n",
    "    seurat <- RunPCA(seurat, npcs = 50, verbose = FALSE)\n",
    "    seurat <- RunUMAP(seurat, reduction = \"pca\", dims = 1:50)\n",
    "    seurat <- FindNeighbors(seurat, dims = 1:50, verbose = FALSE)\n",
    "    seurat <- FindClusters(seurat, verbose = FALSE, resolution = 0.5)\n",
    "    #print(DimPlot(seurat, label = TRUE))\n",
    "    ''')\n",
    "    ## run DoubletFinder\n",
    "    print('\\t\\tRunning DoubletFinder...')\n",
    "    ro.r('''\n",
    "    ## pK Identification (no ground-truth) ---------------------------------------------------------------------------------------\n",
    "    sweep.res.list <- paramSweep_v3(seurat, PCs = 1:50, num.cores = n_core, sct = FALSE)\n",
    "    sweep.stats <- summarizeSweep(sweep.res.list, GT = FALSE)\n",
    "    bcmvn <- find.pK.noPlot(sweep.stats)\n",
    "    \n",
    "    ## Homotypic Doublet Proportion Estimate -------------------------------------------------------------------------------------\n",
    "    homotypic.prop <- modelHomotypic(seurat@meta.data$seurat_clusters)           ## ex: annotations <- seurat.list[[1]]@meta.data$ClusteringResults\n",
    "    nExp_poi <- round(0.1*length(seurat@meta.data$seurat_clusters))  # I guess that doublet formation rate is higher than the ~7.5% estimated from 10x if doublets are present in input cell suspension -> set to 10%  ## Assuming 7.5% doublet formation rate - tailor for your dataset\n",
    "    nExp_poi.adj <- round(nExp_poi*(1-homotypic.prop))\n",
    "    \n",
    "    ## Run DoubletFinder with varying classification stringencies ----------------------------------------------------------------\n",
    "    seurat <- doubletFinder_v3(seurat, \n",
    "                                              PCs = 1:50, \n",
    "                                              pN = 0.25, \n",
    "                                              pK = as.numeric(as.character(bcmvn$pK[which.max(bcmvn$BCmetric)])), \n",
    "                                              nExp = nExp_poi, \n",
    "                                              reuse.pANN = FALSE, \n",
    "                                              sct = FALSE)\n",
    "    \n",
    "    seurat <- doubletFinder_v3(seurat, \n",
    "                                              PCs = 1:50, \n",
    "                                              pN = 0.25, \n",
    "                                              pK = as.numeric(as.character(bcmvn$pK[which.max(bcmvn$BCmetric)])), \n",
    "                                              nExp = nExp_poi.adj, \n",
    "                                              reuse.pANN = paste0(\"pANN_0.25_\",as.character(bcmvn$pK[which.max(bcmvn$BCmetric)]),\"_\",nExp_poi), \n",
    "                                              sct = FALSE)\n",
    "    ''')\n",
    "       \n",
    "    \n",
    "    ## get results   \n",
    "    print('\\t\\tCollect results...')\n",
    "    ro.r('''\n",
    "    results <- seurat@meta.data[,6:8]\n",
    "    colnames(results) <- c(\"pANN\",\"DF_classifications_1\",\"DF_classifications_2\")\n",
    "    ''')\n",
    "    \n",
    "    # sct preprocessing\n",
    "    ## create Seurat object    \n",
    "    ro.r('''\n",
    "    seurat <- CreateSeuratObject(counts = data_mat, project = \"0\", min.cells = 0, min.features = 0)\n",
    "    ''')   \n",
    "    ## preprocessing\n",
    "    print('\\tDoublet Detection with SCT normalization...')\n",
    "    print('\\t\\tPreprocessing...')\n",
    "    ro.r('''\n",
    "    seurat <- SCTransform(seurat, verbose = FALSE)\n",
    "    seurat <- RunPCA(seurat, npcs = 50, verbose = FALSE)\n",
    "    seurat <- RunUMAP(seurat, reduction = \"pca\", dims = 1:50)\n",
    "    seurat <- FindNeighbors(seurat, dims = 1:50, verbose = FALSE)\n",
    "    seurat <- FindClusters(seurat, verbose = FALSE, resolution = 0.5)\n",
    "    #print(DimPlot(seurat, label = TRUE))\n",
    "    ''')\n",
    "    ## run DoubletFinder\n",
    "    print('\\t\\tRunning DoubletFinder...')\n",
    "    ro.r('''\n",
    "    ## pK Identification (no ground-truth) ---------------------------------------------------------------------------------------\n",
    "    sweep.res.list <- paramSweep_v3(seurat, PCs = 1:50, num.cores = n_core, sct = TRUE)\n",
    "    sweep.stats <- summarizeSweep(sweep.res.list, GT = FALSE)\n",
    "    bcmvn <- find.pK.noPlot(sweep.stats)\n",
    "    \n",
    "    ## Homotypic Doublet Proportion Estimate -------------------------------------------------------------------------------------\n",
    "    homotypic.prop <- modelHomotypic(seurat@meta.data$seurat_clusters)           ## ex: annotations <- seurat.list[[1]]@meta.data$ClusteringResults\n",
    "    nExp_poi <- round(0.1*length(seurat@meta.data$seurat_clusters))  # I guess that doublet formation rate is higher than the ~7.5% estimated from 10x if doublets are present in input cell suspension -> set to 10%  ## Assuming 7.5% doublet formation rate - tailor for your dataset\n",
    "    nExp_poi.adj <- round(nExp_poi*(1-homotypic.prop))\n",
    "    \n",
    "    ## Run DoubletFinder with varying classification stringencies ----------------------------------------------------------------\n",
    "    seurat <- doubletFinder_v3(seurat, \n",
    "                                              PCs = 1:50, \n",
    "                                              pN = 0.25, \n",
    "                                              pK = as.numeric(as.character(bcmvn$pK[which.max(bcmvn$BCmetric)])), \n",
    "                                              nExp = nExp_poi, \n",
    "                                              reuse.pANN = FALSE, \n",
    "                                              sct = TRUE)\n",
    "    \n",
    "    seurat <- doubletFinder_v3(seurat, \n",
    "                                              PCs = 1:50, \n",
    "                                              pN = 0.25, \n",
    "                                              pK = as.numeric(as.character(bcmvn$pK[which.max(bcmvn$BCmetric)])), \n",
    "                                              nExp = nExp_poi.adj, \n",
    "                                              reuse.pANN = paste0(\"pANN_0.25_\",as.character(bcmvn$pK[which.max(bcmvn$BCmetric)]),\"_\",nExp_poi), \n",
    "                                              sct = TRUE)\n",
    "    ''')\n",
    "    \n",
    "    \n",
    "    ## get results   \n",
    "    print('\\t\\tCollect results...')\n",
    "    ro.r('''\n",
    "    results <- cbind(results, seurat@meta.data[,8:10])\n",
    "    colnames(results) <- c(\"pANN\",\"DF_classifications_1\",\"DF_classifications_2\", \"pANN.sct\",\"DF_classifications_1.sct\",\"DF_classifications_2.sct\")\n",
    "    ''')\n",
    "    print('\\t\\tAdd results to anndata...')\n",
    "    results = ro.globalenv['results']\n",
    "    \n",
    "    # check if results are already present in adata.obs and delete\n",
    "    if 'pANN' in adata.obs.columns:\n",
    "        del adata.obs[[\"pANN\",\"DF_classifications_1\",\"DF_classifications_2\", \"pANN.sct\",\"DF_classifications_1.sct\",\"DF_classifications_2.sct\"]]\n",
    "    \n",
    "    adata.obs = pd.merge(adata.obs,results, left_index=True, right_index=True) \n",
    "    \n",
    "    adata.obs.loc[:,'df_doublets'] = False\n",
    "    adata.obs.loc[adata.obs.loc[:,'DF_classifications_1']=='Doublet','df_doublets'] = True\n",
    "    adata.obs.loc[adata.obs.loc[:,'DF_classifications_1.sct']=='Doublet','df_doublets'] = True\n",
    "    \n",
    "    print('\\n\\n------------------------------------------------------------------------------------\\n------------------------------------------------------------------------------------' )\n",
    "    print('\\nDoubletFinder doublet rate: ', adata.obs['df_doublets'].value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',adata.obs['df_doublets'].value_counts()[1],' cells)' )\n",
    "    \n",
    "    #return adata   \n",
    "    \n",
    "\n",
    "    \n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "####################################################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "def run_scDblFinder_ATAC(adata, repeats_file='/mnt/ssd/Genomes/mm10/Repeats/AMULET_Exclusion_List_Regions/AMULET_exclusion_regions_noChr.bed', force_reload=False, layer=None, n_core=64, max_memory_gb=128):\n",
    "    '''\n",
    "    adata: adata object to normalize\n",
    "    repeats_file: Path to BED file with repeats and other exclusion regions e.g. '/mnt/ssd/Genomes/mm10/Repeats/AMULET_Exclusion_List_Regions/AMULET_exclusion_regions_noChr.bed'\n",
    "    layer: layer to use for normalization. Default = None -> use .X\n",
    "    force_reload: Force transfer of count data to R\n",
    "    '''\n",
    "    \n",
    "    import rpy2\n",
    "    import rpy2.robjects as ro\n",
    "    import gc\n",
    "\n",
    "       \n",
    "    print('Finding scATAC-seq doublets with scDblFinder:')\n",
    "    # load packages\n",
    "    ro.globalenv['repeats_file'] = repeats_file\n",
    "    ro.globalenv['n_core'] = n_core\n",
    "    ro.globalenv['max_memory'] = max_memory_gb #/n_core\n",
    "    ro.r('''\n",
    "    print(paste0(\"Cores: \", n_core))\n",
    "    print(paste0(\"Memory: \", max_memory))\n",
    "    ''')\n",
    "    ro.r('''\n",
    "\n",
    "    # Analysis\n",
    "    library(Seurat)\n",
    "    library(sctransform)\n",
    "    library(scDblFinder)\n",
    "    library(SingleCellExperiment)\n",
    "    library(scater)\n",
    "    library(pastecs)\n",
    "    library(GenomicRanges)\n",
    "\n",
    "    # Parallelization\n",
    "    library(\"BiocParallel.FutureParam\")\n",
    "    register(FutureParam())\n",
    "    plan(multicore, workers=n_core)\n",
    "    options(future.globals.maxSize = max_memory * 1024^3)\n",
    "    ''')\n",
    "    # transfer data\n",
    "    print('\\tTransfer data...')\n",
    "    \n",
    "    # check if data is in R workspace\n",
    "    if ro.r('''exists('data_mat')''')[0] == 1:\n",
    "        # check if data has same shape\n",
    "        if ro.globalenv['data_mat'].shape == adata.X.T.shape:\n",
    "            load_data = False\n",
    "            print('\\t\\tFound data matrix of same shape. Skipping data transfer...')\n",
    "        else:\n",
    "            load_data = True\n",
    "    else:\n",
    "        load_data = True\n",
    "        \n",
    "    if force_reload:\n",
    "        load_data = True\n",
    "    \n",
    "    if load_data:\n",
    "        if layer is None:\n",
    "            ro.globalenv['data_mat'] = adata.X.T#.toarray()\n",
    "            ro.globalenv['obs_names'] = adata.obs_names\n",
    "            ro.globalenv['var_names'] = adata.var_names\n",
    "        else:\n",
    "            print('\\tUsing layer \\'', layer,'\\'...')\n",
    "            ro.globalenv['data_mat'] = adata.layers[layer].T#.toarray()\n",
    "            ro.globalenv['obs_names'] = adata.obs_names\n",
    "            ro.globalenv['var_names'] = adata.var_names\n",
    "        \n",
    "        ro.r('''\n",
    "        rownames(data_mat) <- var_names\n",
    "        colnames(data_mat) <- obs_names\n",
    "        ''') \n",
    "        \n",
    "    # prepare exclusion list\n",
    "    ro.r('''\n",
    "    repeats <- read.delim(repeats_file, header=FALSE)\n",
    "    repeats <- makeGRangesFromDataFrame(repeats, seqnames.field = \"V1\", start.field = \"V2\", end.field = \"V3\")\n",
    "    #repeats <- GRanges(\"6\", IRanges(1000,2000))\n",
    "    \n",
    "    otherChroms <- GRanges(c(\"M\",\"chrM\",\"MT\",\"X\",\"Y\",\"chrX\",\"chrY\"),IRanges(1L,width=10^8))\n",
    "    \n",
    "    toExclude <- suppressWarnings(c(repeats, otherChroms))\n",
    "    ''')\n",
    "    \n",
    "    # get fragments file path\n",
    "    ro.globalenv['fragments'] = adata.uns['files']['fragments']\n",
    "#     ro.r('''\n",
    "#     fragments <- system.file(\"extdata\", \"example_fragments.tsv.gz\", package=\"scDblFinder\")\n",
    "#     ''')\n",
    "    \n",
    "    # create SingleCellExperiment object    \n",
    "    ro.r('''\n",
    "    sce <- SingleCellExperiment(assays=list(counts=data_mat))\n",
    "    ''')   \n",
    "    \n",
    "    ## run AMULET\n",
    "    print('\\tRunning AMULET...')\n",
    "    ro.r('''\n",
    "    #AMULET\n",
    "    results <- amulet(fragments, regionsToExclude=toExclude, fullInMemory=TRUE)#, BPPARAM=MulticoreParam(n_core))\n",
    "    colnames(results) <- paste0('amulet.', colnames(results))\n",
    "    ''')\n",
    "    \n",
    "    ## run scDblFinder\n",
    "    print('\\tRunning scDblFinder...')\n",
    "    ro.r('''\n",
    "    #scDblFinder\n",
    "    colData(sce)$scoresDoubletDensity <- computeDoubletDensity(sce)\n",
    "    sce <- scDblFinder(sce, aggregateFeatures=TRUE, nfeatures=25, processing=\"normFeatures\", clusters = FALSE) #, dbr=0.1)\n",
    "    ''')\n",
    "    \n",
    "    ## get results   \n",
    "    print('\\tCollect results...')\n",
    "    ro.r('''\n",
    "    results$atac.scDblFinder.p <- 1-colData(sce)[row.names(results), \"scDblFinder.score\"]\n",
    "    results$atac.combined <- apply(results[,c(\"atac.scDblFinder.p\", \"amulet.p.value\")], 1, FUN=function(x){\n",
    "      x[x<0.001] <- 0.001 # prevent too much skew from very small or 0 p-values\n",
    "      suppressWarnings(aggregation::fisher(x))\n",
    "    })\n",
    "    results$atac.combined.score <- -results$atac.combined + 1\n",
    "    \n",
    "    #results$atac.combined.class <- doubletThresholding(data.frame('score'=results$atac.combined.score), dbr=0.1)\n",
    "    ''')\n",
    "    \n",
    "    \n",
    "    print('\\tAdd results to anndata...')\n",
    "    results = ro.globalenv['results']\n",
    "    \n",
    "    # check if results are already present in adata.obs and delete\n",
    "    if results.columns[0] in adata.obs.columns:\n",
    "        del adata.obs[results.columns]\n",
    "    \n",
    "    adata.obs = pd.merge(adata.obs,results, left_index=True, right_index=True) #adata.obs[[\"scDblFinder.class.sct\", \"scDblFinder.score.sct\"]] = results.copy()\n",
    "    \n",
    "#     adata.obs.loc[:,'atac_sdf_doublets'] = False\n",
    "#     adata.obs.loc[adata.obs.loc[:,'atac.combined.class']=='doublet','sdf_doublets'] = True\n",
    "    \n",
    "#     print('\\n\\n------------------------------------------------------------------------------------\\n------------------------------------------------------------------------------------' )\n",
    "#     print('\\nATAC scDblFinder doublet rate:', adata.obs['atac_sdf_doublets'].value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',adata.obs['atac_sdf_doublets'].value_counts()[1],' cells)' )\n",
    "    \n",
    "#     return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read('/storage/scRNA-seq/scRNA-seq_iPSC_IGFRL-KO/cellranger/MUC18397/count_matrices/MUC18397_raw_feature_bc_matrix_filtered.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5354, 17499)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['sample','leiden','n_counts','log_counts','n_genes','log_genes','mt_frac','rp_frac'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0), ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doublet Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrublet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce.pp.scrublet(adata, sim_doublet_ratio=5, expected_doublet_rate=0.1, threshold=0.25)\n",
    "sce.pl.scrublet_score_distribution(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['scrublet_doublets_cat'] = adata.obs['predicted_doublet'].astype(str).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['n_genes','n_counts','scrublet_doublets_cat','doublet_score'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0), ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_SCDS(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scds doublet rate:', (adata.obs['hybrid_class'] == 'doublet').value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',(adata.obs['hybrid_class'] == 'doublet').value_counts()[1],' cells)' )\n",
    "print('Cut-off:', min(adata[adata.obs['hybrid_class'] == 'doublet'].obs['hybrid_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust cut-off as doublet rate is too high \n",
    "cut_off = 1 #min(adata[adata.obs['hybrid_class'] == 'doublet'].obs['hybrid_score'])\n",
    "\n",
    "with rc_context({'figure.figsize': (8, 3)}):\n",
    "    sb.distplot(adata.obs['hybrid_score'], kde=True, bins=100)\n",
    "    sb.distplot(adata.obs['hybrid_score'][(adata.obs['hybrid_score']>0.35) & (adata.obs['hybrid_score']<2)], kde=True, bins=100)\n",
    "    plt.axvline(cut_off, 0, 1, color=\"black\", lw=1).set_linestyle(\"--\")\n",
    "\n",
    "print('Scds doublet rate:', (adata.obs['hybrid_score'] > cut_off).value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',(adata.obs['hybrid_score'] > cut_off).value_counts()[1],' cells)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['hybrid_class'] = pd.Categorical(adata.obs['hybrid_class'], categories=['doublet','singlet'])\n",
    "adata.obs['hybrid_class'] = 'singlet'\n",
    "adata.obs.loc[adata.obs['hybrid_score'] > cut_off,'hybrid_class'] = 'doublet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scds doublet rate:', (adata.obs['hybrid_class_sct'] == 'doublet').value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',(adata.obs['hybrid_class_sct'] == 'doublet').value_counts()[1],' cells)' )\n",
    "print('Cut-off:', min(adata[adata.obs['hybrid_class_sct'] == 'doublet'].obs['hybrid_score_sct']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust cut-off as doublet rate is too high \n",
    "cut_off = 0.6 #min(adata[adata.obs['hybrid_class_sct'] == 'doublet'].obs['hybrid_score_sct'])\n",
    "\n",
    "with rc_context({'figure.figsize': (8, 3)}):\n",
    "    sb.distplot(adata.obs['hybrid_score_sct'], kde=True, bins=100)\n",
    "    sb.distplot(adata.obs['hybrid_score_sct'][(adata.obs['hybrid_score_sct']>0.25) & (adata.obs['hybrid_score_sct']<0.85)], kde=True, bins=100)\n",
    "    plt.axvline(cut_off, 0, 1, color=\"black\", lw=1).set_linestyle(\"--\")\n",
    "\n",
    "print('Scds doublet rate:', (adata.obs['hybrid_score_sct'] > cut_off).value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',(adata.obs['hybrid_score_sct'] > cut_off).value_counts()[1],' cells)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['hybrid_class_sct'] = pd.Categorical(adata.obs['hybrid_class_sct'], categories=['doublet','singlet'])\n",
    "adata.obs['hybrid_class_sct'] = 'singlet'\n",
    "adata.obs.loc[adata.obs['hybrid_score_sct'] > cut_off,'hybrid_class_sct'] = 'doublet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.loc[:,'scds_doublets'] = False\n",
    "adata.obs.loc[adata.obs.loc[:,'hybrid_class']=='doublet','scds_doublets'] = True\n",
    "adata.obs.loc[adata.obs.loc[:,'hybrid_class_sct']=='doublet','scds_doublets'] = True\n",
    "\n",
    "print('Scds doublet rate:', adata.obs['scds_doublets'].value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',adata.obs['scds_doublets'].value_counts()[1],' cells)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['n_genes','n_counts','hybrid_class','hybrid_score','hybrid_class_sct','hybrid_score_sct'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0), ncols=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scDblFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_scDblFinder(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['n_genes','n_counts','scDblFinder.class','scDblFinder.score','scDblFinder.class.sct','scDblFinder.score.sct'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0), ncols=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoubletFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Creating 1785 artificial doublets...\"\n",
      "[1] \"Creating Seurat object...\"\n",
      "[1] \"Running SCTransform...\"\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "[1] \"Running PCA...\"\n",
      "[1] \"Calculating PC distance matrix...\"\n",
      "[1] \"Computing pANN...\"\n",
      "[1] \"Classifying doublets..\"\n",
      "\t\tCollect results...\n",
      "\t\tAdd results to anndata...\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "DoubletFinder doublet rate:  16.100112065745236 % ( 862  cells)\n"
     ]
    }
   ],
   "source": [
    "run_DoubletFinder(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['n_genes','n_counts','pANN','DF_classifications_1','DF_classifications_2'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0), ncols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['n_genes','n_counts','pANN.sct','DF_classifications_1.sct','DF_classifications_2.sct'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0), ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doublet Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['dd_doublets']=0\n",
    "adata.obs['dd_scores']=0\n",
    "adata.obs['dd_log_p_values']=0\n",
    "adata.obs['dd_voting_average']=0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('/home/michi/Projects/scRNA-seq_iPSC_IGFRL-KO_Notebooks/Files/S6_IIR-KO_DoubletDetection_clf.pkl', 'rb') as file:\n",
    "    adata_clf = pickle.load(file)\n",
    "    \n",
    "with open('/home/michi/Projects/scRNA-seq_iPSC_IGFRL-KO_Notebooks/Files/S6_IIR-KO_DoubletDetection_dd_doublets.pkl', 'rb') as file:\n",
    "    adata_dd_doublets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:00)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 55 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 55 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:01)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 63 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 64 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:01)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 55 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 63 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:01)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 57 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 61 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 55 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 56 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 63 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 63 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 62 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:01)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 58 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 59 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n",
      "computing PCA\n",
      "Note that scikit-learn's randomized PCA might not be exactly reproducible across different computational platforms. For exact reproducibility, choose `svd_solver='arpack'.`\n",
      "    with n_comps=30\n",
      "    finished (0:00:02)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 30\n",
      "    finished: added to `.uns['neighbors']`\n",
      "    `.obsp['distances']`, distances for each pair of neighbors\n",
      "    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\n",
      "running Leiden clustering\n",
      "    finished: found 60 clusters and added\n",
      "    'clusters', the cluster labels (adata.obs, categorical) (0:00:00)\n"
     ]
    }
   ],
   "source": [
    "adata_clf = doubletdetection.BoostClassifier(n_iters=200, clustering_algorithm='leiden', standard_scaling=True, n_jobs=64, random_state=123)\n",
    "adata_dd_doublets = adata_clf.fit(adata.X).predict(p_thresh=1e-6, voter_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=doubletdetection.plot.convergence(adata_clf, show=False, p_thresh=1e-6, voter_thresh=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=threshold(adata_clf, show=True, p_step=5, log_p_grid=np.arange(-15, -1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "doubletdetection.plot.umap_plot(adata.X, adata_dd_doublets, random_state=1, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/michi/Projects/scMultiome_FVF_Crypts_P21021_Notebooks/Files/S6_IIR-KO_DoubletDetection_clf.pkl', 'wb') as output:\n",
    "    pickle.dump(adata_clf, output, -1)\n",
    "    \n",
    "with open('/home/michi/Projects/scMultiome_FVF_Crypts_P21021_Notebooks/Files/S6_IIR-KO_DoubletDetection_dd_doublets.pkl', 'wb') as output:\n",
    "    pickle.dump(adata_dd_doublets, output, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['dd_doublets']=adata_dd_doublets.astype('bool')\n",
    "adata.obs['dd_-log_p_values']=np.mean(adata_clf.all_log_p_values_, axis=0) * -1\n",
    "adata.obs['dd_voting_average']=adata_clf.voting_average_\n",
    "adata.obs['dd_scores']=np.mean(adata_clf.all_scores_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['dd_doublets_cat'] = adata.obs['dd_doublets'].astype(str).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['n_genes','n_counts','dd_doublets_cat','dd_-log_p_values','dd_voting_average','dd_scores'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0), ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DoubletDetection doublet rate:', adata.obs['dd_doublets'].value_counts()[1]/adata.obs['sample'].value_counts()[0]*100, '% (',adata.obs['dd_doublets'].value_counts()[1],' cells)' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.model.SCVI.setup_anndata(adata)\n",
    "vae = scvi.model.SCVI(adata, n_hidden=256, n_latent=20, gene_likelihood='nb')\n",
    "vae.train()\n",
    "solo = scvi.external.SOLO.from_scvi_model(vae)\n",
    "solo.train()\n",
    "predictions = solo.predict()\n",
    "predictions['solo_doublet_class'] = solo.predict(soft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.index = [index[:-2] for index in predictions.index]\n",
    "predictions.columns = ['solo_doublet_score', 'solo_singlet_score','solo_doublet_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=sb.jointplot(data=predictions, x='solo_singlet_score', y='solo_doublet_score', s=2, kind='scatter', linewidth=0, space=0, marginal_kws=dict(bins=200, kde=True)) #, hue='solo_doublet_class',data=predictions))\n",
    "p.plot_joint(sb.scatterplot, color=\"black\", s=3 ,data=predictions, linewidth=0)\n",
    "p.plot_joint(sb.scatterplot, s=2, hue='solo_doublet_class',data=predictions, linewidth=0)\n",
    "p.ax_joint.axvline(x=0, ymin=0, ymax=max(predictions['solo_doublet_score']), color=\"black\", lw=0.5).set_linestyle(\"--\")\n",
    "p.ax_joint.axhline(y=0, xmin=0, xmax=max(predictions['solo_singlet_score']), color=\"black\", lw=0.5).set_linestyle(\"--\")\n",
    "p.ax_joint.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SOLO doublet rate:', sum(predictions.solo_doublet_class == 'doublet')/adata.n_obs*100, '% (',sum(predictions.solo_doublet_class == 'doublet'),' cells)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adata.obs = pd.concat([adata.obs, predictions], axis=1)\n",
    "adata.obs['solo_doublets'] = False\n",
    "adata.obs.loc[adata.obs['solo_doublet_class'] == 'doublet','solo_doublets'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['solo_doublet_class','solo_doublet_score', 'solo_singlet_score'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0), ncols=3, cmap='RdBu_r', vcenter=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up doublets from different tools\n",
    "adata.obs['doublet_calls'] = adata.obs[['predicted_doublet','dd_doublets','solo_doublets','df_doublets','sdf_doublets','scds_doublets']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['sample','doublet_calls'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of calls\n",
    "print(adata.obs['doublet_calls'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.loc[:,'final_doublets'] = False\n",
    "adata.obs.loc[adata.obs.loc[:,'doublet_calls'] > 3,'final_doublets'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['final_doublets_cat'] = adata.obs['final_doublets'].astype(str).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['final_doublets_cat','doublet_calls'], size=20, add_outline=True, alpha=1, outline_width=(0.3, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of doublets:\n",
      "False    4821\n",
      "True      533\n",
      "Name: final_doublets, dtype: int64\n",
      "\n",
      "Overall doublet rate:  9.955173701905117 %\n"
     ]
    }
   ],
   "source": [
    "# Number of final doublets\n",
    "print('Number of doublets:')\n",
    "print(adata.obs['final_doublets'].value_counts())\n",
    "\n",
    "# Percentage:\n",
    "print('\\nOverall doublet rate: ',adata.obs['final_doublets'].value_counts()[1]/len(adata.obs['final_doublets'])*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S6_IIR-KO    5354\n",
      "Name: sample, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5354, 17499)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annotate the data sets\n",
    "print(adata.obs['sample'].value_counts())\n",
    "\n",
    "# Checking the total size of the data set\n",
    "adata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "adata.write('/storage/scRNA-seq/scRNA-seq_iPSC_IGFRL-KO/cellranger/MUC18397/count_matrices/MUC18397_raw_feature_bc_matrix_filtered_markedDoublets.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scAnalysis_sc1.9_ad0.8_mu0.1.2_md0.2_R4.1_FVF",
   "language": "python",
   "name": "scanalysis_sc1.9_ad0.8_mu0.1.2_md0.2_r4.1_fvf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
